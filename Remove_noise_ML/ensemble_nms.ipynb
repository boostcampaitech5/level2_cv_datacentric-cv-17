{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "import tensorflow as tf\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#합칠 json파일이 모인 위치\n",
    "load_train = \"./\"\n",
    "\n",
    "# 한 이미지가 가질 최대 단어수\n",
    "max_output_size = 500\n",
    "#iou_threshold = 0.5\n",
    "iou_threshold = 0.5\n",
    "\n",
    "#업데이트 할 annotation json 파일 이름\n",
    "annotation_json = \"annotation.json\"\n",
    "#annotation.json위치\n",
    "load_path = \"./\"\n",
    "#업데이트 한 json파일 위치와 이름\n",
    "save_dir = \"./ensemble.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_dict = {}\n",
    "scores_dict = {}\n",
    "\n",
    "for i in range(1):    \n",
    "    with open(load_train+f\"split_{i}.json\", 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        bboxes = data[\"images\"]\n",
    "        key_list_b = list(data[\"images\"].keys())\n",
    "    \n",
    "    with open(load_train+f\"split_{i}_s.json\", 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        scores = data[\"images\"]\n",
    "        key_list_s = list(data[\"images\"].keys())\n",
    "\n",
    "    key_list = list(set(key_list_b)&set(key_list_s))\n",
    "    \n",
    "    for key in key_list:\n",
    "        if key not in boxes_dict:\n",
    "            boxes_dict[key] = []\n",
    "\n",
    "        for num in bboxes[key][\"words\"]:\n",
    "            pnt = bboxes[key][\"words\"][num][\"points\"]\n",
    "            x1= min(pnt[0][0],pnt[1][0],pnt[2][0],pnt[3][0])\n",
    "            y1= min(pnt[0][1],pnt[1][1],pnt[2][1],pnt[3][1])\n",
    "            x2= max(pnt[0][0],pnt[1][0],pnt[2][0],pnt[3][0])\n",
    "            y2= max(pnt[0][1],pnt[1][1],pnt[2][1],pnt[3][1])\n",
    "            boxes_dict[key].append([x1,y1,x2,y2])\n",
    "\n",
    "    for key in key_list:\n",
    "        if key not in scores_dict:\n",
    "            scores_dict[key] = []\n",
    "\n",
    "        for num in scores[key][\"words\"]:\n",
    "            pnt = scores[key][\"words\"][num][\"points\"]\n",
    "            score = pnt[0]\n",
    "            scores_dict[key].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_dict = {}\n",
    "\n",
    "for key in key_list:\n",
    "    if (not boxes_dict[key]) or (not scores_dict[key]):\n",
    "        continue\n",
    "    box = torch.Tensor(list(boxes_dict[key]))\n",
    "    score = torch.Tensor(list(scores_dict[key]))\n",
    "    ans =  tf.image.non_max_suppression(box, score, max_output_size, iou_threshold)\n",
    "    for i in ans:\n",
    "        if key not in ans_dict:\n",
    "            ans_dict[key] = []\n",
    "        ans_dict[key].append(boxes_dict[key][i])\n",
    "\n",
    "nms_dict = {}\n",
    "for key in ans_dict.keys():\n",
    "    for x1,y1,x2,y2 in ans_dict[key]:\n",
    "        point = [[x1,y1], [x2,y1], [x2,y2], [x1,y2]]\n",
    "        if key not in nms_dict:\n",
    "            nms_dict[key] = []\n",
    "        nms_dict[key].append(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(load_path + annotation_json, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "    images = copy.deepcopy(data[\"images\"])\n",
    "\n",
    "    for key in images.keys():\n",
    "        if key not in nms_dict:\n",
    "            continue\n",
    "\n",
    "        images[key][\"words\"] = {}\n",
    "\n",
    "        for idx in range(len(ans_dict[key])):\n",
    "            num = (\"000\" + str(idx+1))[-5:]\n",
    "            x1,y1,x2,y2 = ans_dict[key][idx]\n",
    "\n",
    "            images[key][\"words\"][num] = {\n",
    "                \"transcription\" : \" \",\n",
    "                \"point\" : [[x1,y1],[x2,y1],[x2,y2],[x1,y2]],\n",
    "                \"orientation\": \"Horizontal\",\n",
    "                \"language\": None,\n",
    "                \"tags\": [],\n",
    "                \"confidence\": None,\n",
    "                \"illegibility\": False }\n",
    "\n",
    "    with open(save_dir,'w') as train_writer:\n",
    "        json.dump({\n",
    "            'images' : images\n",
    "        }, train_writer, indent=4)\n",
    "\n",
    "    print('\\nCreating %s... Done !' %save_dir)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
